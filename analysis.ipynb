{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3ce4801-e7ff-4431-8b64-3a61a4b1ca72",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c2e2bf6-98a1-4bc7-9349-8ec836050c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from eelbrain import *\n",
    "import scipy, mne, os, shutil, pdb, importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "root_folder = 'data_path' # path to DRUM dataset\n",
    "subjects_dir = f'{root_folder}/mri' # copy freesurfer fsaverage files here\n",
    "meg_folder = f'{root_folder}/meg'\n",
    "output_folder = 'output_path' # path to output folder\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "    \n",
    "subjects = [f for f in os.listdir(meg_folder) if f[0]=='R'] # get subject list\n",
    "subjects.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2343aa-688b-446c-9f10-fd55bf347ef6",
   "metadata": {},
   "source": [
    "# make sourcespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f601d1d3-bb6c-4c84-9410-273c9d2a44e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make subjects_dir mri folders and scaled source spaces\n",
    "# freesurfer fsaverage files need to be in the subjects_dir\n",
    "for subject in subjects:\n",
    "    if not os.path.exists(f'{subjects_dir}/{subject}/bem/{subject}-ico-4-src.fif'):\n",
    "        print(f'making {subject}')\n",
    "        os.makedirs(f'{subjects_dir}/{subject}/bem')\n",
    "        shutil.copyfile(f'{meg_folder}/{subject}/MRI scaling parameters.cfg', f'{subjects_dir}/{subject}/MRI scaling parameters.cfg')\n",
    "        mne.scale_source_space(subject, f'{{subject}}-ico-4-src.fif', subjects_dir=subjects_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983dc631-6d7a-47e3-b9f8-259982c067c7",
   "metadata": {},
   "source": [
    "# make resting beta power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c424ced-741e-4071-9240-97f4bb09c238",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    if subject == 'R26672': # fix for R2667 is not needed for resting data\n",
    "        continue\n",
    "    for visit in ['visit1', 'visit2']:\n",
    "        fwdfile = f'{meg_folder}/{subject}/{subject}_{visit}_resting-ico-4-fwd.fif'\n",
    "        snds = []\n",
    "        for i in range(1,3): # loop over resting 1 and 2\n",
    "            rawfile = f'{meg_folder}/{subject}/{subject}_{visit}_resting{i}-raw.fif'\n",
    "            if not os.path.exists(rawfile):\n",
    "                print(f'file not found: {subject}_{visit}_resting{i}')\n",
    "                continue\n",
    "            print(f'loading {subject}_{visit}_resting{i}')\n",
    "            raw = mne.io.read_raw_fif(rawfile)\n",
    "            \n",
    "            # source localization\n",
    "            covfile = f'{rawfile[:-7]}cov.fif'\n",
    "            fwd = mne.read_forward_solution(fwdfile)\n",
    "            cov = mne.read_cov(covfile)\n",
    "            invsol = mne.minimum_norm.make_inverse_operator(raw.info, fwd, cov, fixed=True, depth=0.8)\n",
    "            stc1 = mne.minimum_norm.apply_inverse_raw(raw, invsol, lambda2 = 1, method='MNE')\n",
    "            snd1 = load.fiff.stc_ndvar(stc1, 'fsaverage', 'ico-4', subjects_dir=subjects_dir)\n",
    "            snds.append(snd1.sub(time=(5, snd1.time.tmax-5)))\n",
    "            del stc1, snd1\n",
    "        if len(snds) == 0:\n",
    "            continue\n",
    "        # concatenate resting 1 and 2\n",
    "        snd1 = concatenate(snds, 'time')\n",
    "        del snds\n",
    "        \n",
    "        # make psd on 15s blocks of the data\n",
    "        nblocks = snd1.time.tmax/15\n",
    "        psds = []\n",
    "        for i in range(int(np.floor(nblocks))):\n",
    "            print('making psd block', i*15, 's - ', (i+1)*15, 's', ' '*20, end='\\r')\n",
    "            psds.append(psd_welch(snd1.sub(time=(i*15,(i+1)*15)), n_per_seg=256, n_overlap=128).sub(frequency=(1,40)))\n",
    "        psd = combine(psds).mean('case')\n",
    "        \n",
    "        save.pickle(psd, f'{output_folder}/{subject}_{visit}_resting_psd.pkl')\n",
    "        \n",
    "        # plot average psds across the whole brain and across rolandic roi\n",
    "        rolandicROI = list(set([l for l in psd.source.parc.as_labels() if 'central' in l]))\n",
    "        psd1 = psd.mean('source') # whole brain average\n",
    "        psd1.name = 'whole brain'\n",
    "        psd2 = psd.sub(source=rolandicROI).mean('source') # rolandic roi average\n",
    "        psd2.name = 'rolandic ROI'\n",
    "        p = plot.UTS([[psd1, psd2]])\n",
    "        p.save(f'{output_folder}/plots_psd_{subject}_{visit}_resting.png')\n",
    "        p.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546b3207-283a-4928-a10d-434652ab353d",
   "metadata": {},
   "source": [
    "# make visual beta power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf9f530-4e21-46f7-9cf8-5c2adb5a5522",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['fam', 'mm', 'pn', 'pd']\n",
    "\n",
    "for subject in subjects:\n",
    "    for visit in ['visit1', 'visit2']:\n",
    "        fwdfile = f'{meg_folder}/{subject}/{subject}_{visit}_visual-fwd.fif'\n",
    "        for task in tasks:\n",
    "            rawfile = f'{meg_folder}/{subject}/{subject}_{visit}_visual_{task}-raw.fif'\n",
    "            if not os.path.exists(rawfile):\n",
    "                print(f'file not found: {subject}_{visit}_visual_{task}')\n",
    "                continue\n",
    "            print(f'loading {subject}_{visit}_visual_{task}')\n",
    "            raw = mne.io.read_raw_fif(rawfile)\n",
    "            \n",
    "            # source localization\n",
    "            covfile = f'{rawfile[:-7]}cov.fif'\n",
    "            fwd = mne.read_forward_solution(fwdfile)\n",
    "            cov = mne.read_cov(covfile)\n",
    "            invsol = mne.minimum_norm.make_inverse_operator(raw.info, fwd, cov, fixed=True, depth=0.8)\n",
    "            stc1 = mne.minimum_norm.apply_inverse_raw(raw, invsol, lambda2 = 1, method='MNE')\n",
    "            snd1 = load.fiff.stc_ndvar(stc1, 'fsaverage', 'ico-4', subjects_dir=subjects_dir)\n",
    "\n",
    "            # make psd in 15s blocks\n",
    "            nblocks = snd1.time.tmax/15\n",
    "            psds = []\n",
    "            for i in range(int(np.floor(nblocks))):\n",
    "                print('making psd block', i*15, 's - ', (i+1)*15, 's', ' '*20, end='\\r')\n",
    "                psds.append(psd_welch(snd1.sub(time=(i*15,(i+1)*15)), n_per_seg=256, n_overlap=128).sub(frequency=(1,40)))\n",
    "            psd = combine(psds).mean('case')\n",
    "            save.pickle(psd, f'{output_folder}/{subject}_{visit}_visual_{task}_psd.pkl')\n",
    "\n",
    "            # plot average psds across the whole brain and across rolandic roi\n",
    "            rolandicROI = list(set([l for l in psd.source.parc.as_labels() if 'central' in l]))\n",
    "            psd1 = psd.mean('source') # whole brain average\n",
    "            psd1.name = 'whole brain'\n",
    "            psd2 = psd.sub(source=rolandicROI).mean('source') # rolandic roi average\n",
    "            psd2.name = 'rolandic ROI'\n",
    "            p = plot.UTS([[psd1, psd2]])\n",
    "            p.save(f'{output_folder}/plots_psd_{subject}_{visit}_visual_{task}.png')\n",
    "            p.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaa8b1e-b36a-4f68-a288-0c87e5d66e50",
   "metadata": {},
   "source": [
    "# write CSV file beta power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8be3f4-b04a-460b-b773-f85f82c21d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTROLS = ['R2517', 'R2519', 'R2520', 'R2521', 'R2525', 'R2528', 'R2496', 'R2673',] \n",
    "PATIENTS = ['R2527', 'R2540', 'R2546', 'R2598', 'R2615', 'R2617', 'R2664', 'R2667', 'R2668',]\n",
    "\n",
    "# lesion hemisphere\n",
    "LEFT =  ['R2527', 'R2540', 'R2667', 'R2668']\n",
    "RIGHT = ['R2546', 'R2598', 'R2615', 'R2617', 'R2664']\n",
    "\n",
    "psdsubj = dict(C={},P={})\n",
    "beta_band = (13, 25)\n",
    "psdrange = (2, 40)\n",
    "\n",
    "\n",
    "outfile = 'betapower.csv'\n",
    "with open(outfile, 'w+') as f:\n",
    "    f.write(f'subject,group,rel_beta,visit,task\\n') # column headings\n",
    "    \n",
    "# lesion hemisphere\n",
    "outfile2 = 'betapower_lesionhemi.csv'\n",
    "with open(outfile2, 'w+') as f:\n",
    "    f.write(f'subject,group,rel_beta,hemi,lesion,visit,task\\n') # column headings \n",
    "    \n",
    "for subject in subjects:\n",
    "    for visit in ['visit1', 'visit2']:\n",
    "        for task in ['resting', 'visual_fam', 'visual_mm', 'visual_pn', 'visual_pd']:\n",
    "            infile = f'{subject}_{visit}_{task}_psd.pkl'\n",
    "            if not os.path.exists(f'{output_folder}/{infile}'):\n",
    "                print(f'file not found: {infile}')\n",
    "                continue\n",
    "            print(f'loading: {infile}')\n",
    "            psd = load.unpickle(f'{output_folder}/{infile}')\n",
    "            \n",
    "            subject = subject[:5] # this is to combine R26672 and R2667\n",
    "            if subject in CONTROLS:\n",
    "                group = 'C'\n",
    "            else:\n",
    "                group = 'P'\n",
    "            \n",
    "            # rolandic ROI\n",
    "            rolandicROI = list(set([l for l in psd.source.parc.as_labels() if 'central' in l]))\n",
    "            psd2 = psd.sub(source=rolandicROI).mean('source').sub(frequency=psdrange)\n",
    "\n",
    "            # relative power\n",
    "            psd_rel = psd2.copy()\n",
    "            psd_rel.x /= np.sum(psd_rel.x)\n",
    "            rel_beta = psd_rel.sub(frequency=beta_band).sum('frequency')\n",
    "\n",
    "            with open(outfile, 'a+') as f:\n",
    "                f.write(f'{subject},{group},{rel_beta},{visit},{task}\\n')\n",
    "                    \n",
    "            psdL = psd.sub(source=rolandicROI).sub(source='lh').mean('source').sub(frequency=psdrange)\n",
    "            psd_relL = psdL.copy()\n",
    "            psd_relL.x /= np.sum(psd_relL.x)\n",
    "            rel_betaL = psd_relL.sub(frequency=beta_band).sum('frequency')\n",
    "\n",
    "            psdR = psd.sub(source=rolandicROI).sub(source='rh').mean('source').sub(frequency=psdrange)\n",
    "            psd_relR = psdR.copy()\n",
    "            psd_relR.x /= np.sum(psd_relR.x)\n",
    "            rel_betaR = psd_relR.sub(frequency=beta_band).sum('frequency')\n",
    "\n",
    "            with open(outfile2, 'a+') as f:\n",
    "                if subject in LEFT:\n",
    "                    f.write(f'{subject},{group},{rel_betaL},left,ipsi,{visit},{task}\\n')\n",
    "                    f.write(f'{subject},{group},{rel_betaR},right,contra,{visit},{task}\\n')\n",
    "                elif subject in RIGHT:\n",
    "                    f.write(f'{subject},{group},{rel_betaL},left,contra,{visit},{task}\\n')\n",
    "                    f.write(f'{subject},{group},{rel_betaR},right,ipsi,{visit},{task}\\n')\n",
    "                else:\n",
    "                    f.write(f'{subject},{group},{rel_betaL},left,,{visit},{task}\\n')\n",
    "                    f.write(f'{subject},{group},{rel_betaR},right,,{visit},{task}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1516919-e878-43f8-8fdb-ec6486fb3c34",
   "metadata": {},
   "source": [
    "# make ERD ERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784ebc6b-f540-4778-934c-6b16618912a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for subject in subjects:\n",
    "    for visit in ['visit1', 'visit2']:\n",
    "        trigger_file = f'{subject[:5]}_{visit}_visual_triggers.csv' # subject[:5] to combine R26672 and R2667\n",
    "        if not os.path.exists(f'{meg_folder}/{subject[:5]}/{trigger_file}'):\n",
    "            print(f'file not found: {trigger_file}')\n",
    "            continue\n",
    "        print(trigger_file)\n",
    "        triggers = pd.read_csv(f'{meg_folder}/{subject[:5]}/{trigger_file}')\n",
    "        for task in ['mm', 'pn', 'pd']:\n",
    "            rawfile = f'{subject}_{visit}_visual_{task}-raw.fif'\n",
    "            if not os.path.exists(f'{meg_folder}/{subject}/{rawfile}'):\n",
    "                print(f'file not found: {rawfile}')\n",
    "                continue\n",
    "            print(f'loading: {rawfile}')\n",
    "            raw = mne.io.read_raw_fif(f'{meg_folder}/{subject}/{rawfile}')\n",
    "\n",
    "            # source localization\n",
    "            covfile = f'{meg_folder}/{subject}/{rawfile[:-7]}cov.fif'\n",
    "            fwdfile = f'{meg_folder}/{subject}/{subject}_{visit}_visual-fwd.fif'\n",
    "            fwd = mne.read_forward_solution(fwdfile)\n",
    "            cov = mne.read_cov(covfile)\n",
    "            invsol = mne.minimum_norm.make_inverse_operator(raw.info, fwd, cov, fixed=True, depth=0.8)\n",
    "            stc1 = mne.minimum_norm.apply_inverse_raw(raw, invsol, lambda2 = 1, method='MNE')\n",
    "            snd1 = load.fiff.stc_ndvar(stc1, 'fsaverage', 'ico-4', subjects_dir=subjects_dir)\n",
    "            rolandicROI = list(set([l for l in snd1.source.parc.as_labels() if 'central' in l]))\n",
    "            snd1 = snd1.sub(source=rolandicROI)\n",
    "            \n",
    "            tstart = load.unpickle(f'{meg_folder}/{subject}/{rawfile[:-8]}_tstart.pkl')\n",
    "            snd1 = NDVar(snd1.x, (snd1.source, UTS(tstart, snd1.time.tstep, snd1.x.shape[1])))\n",
    "            \n",
    "            epochsR = []\n",
    "            epochsL = []\n",
    "            specgramsL = []\n",
    "            specgramsR = []\n",
    "            specgramsL_lh = []\n",
    "            specgramsL_rh = []\n",
    "            specgramsR_lh = []\n",
    "            specgramsR_rh = []\n",
    "            task_trigs = triggers[triggers['task']==task]\n",
    "            i = 1\n",
    "            for tt, side in zip(task_trigs['t_start'], task_trigs['button_side']):\n",
    "                t = tt\n",
    "                if subject == 'R26672':\n",
    "                    t -=  1214 # get correct trigger times\n",
    "                print(i, len(task_trigs['t_start']), t, ' '*20, end='\\r')\n",
    "                i += 1\n",
    "                if t+3 > snd1.time.tmax:\n",
    "                    print(f'{t+3} > {snd1.time.tmax}')\n",
    "                    continue\n",
    "                epoch = snd1.sub(time=(t-3,t+3))\n",
    "                \n",
    "                # make spectrogram using morlet wavelets\n",
    "                freqs = np.logspace(*np.log10([6, 35]), num=20)\n",
    "                n_cycles = freqs / 2.\n",
    "                fs = 1/epoch.time.tstep\n",
    "                specgram = mne.time_frequency.tfr_array_morlet(epoch.x[np.newaxis,:,:], fs, freqs=freqs, n_cycles=n_cycles, use_fft=True,\n",
    "                                n_jobs=1, decim=1)\n",
    "                specgram = NDVar(np.abs(specgram[0])**2, (epoch.source, Scalar('frequency', freqs), UTS(-3, 1/fs, specgram[0].shape[2])))\n",
    "                specgram_lh = specgram.sub(source='lh').mean('source')\n",
    "                specgram_rh = specgram.sub(source='rh').mean('source')\n",
    "                specgram = specgram.mean('source')\n",
    "                \n",
    "                if side == 'left':\n",
    "                    epochsL.append(epoch)\n",
    "                    specgramsL.append(specgram)\n",
    "                    specgramsL_lh.append(specgram_lh)\n",
    "                    specgramsL_rh.append(specgram_rh)\n",
    "                elif side == 'right':\n",
    "                    epochsR.append(epoch)\n",
    "                    specgramsR.append(specgram)\n",
    "                    specgramsR_lh.append(specgram_lh)\n",
    "                    specgramsR_rh.append(specgram_rh)\n",
    "                \n",
    "                \n",
    "            save.pickle(epochsL, f'{output_folder}/{subject[:5]}_{visit}_visual_{task}_buttonL_epochs.pkl')\n",
    "            save.pickle(epochsR, f'{output_folder}/{subject[:5]}_{visit}_visual_{task}_buttonR_epochs.pkl')\n",
    "            save.pickle(specgramsL, f'{output_folder}/{subject[:5]}_{visit}_visual_{task}_button_specgramsL.pkl')\n",
    "            save.pickle(specgramsR, f'{output_folder}/{subject[:5]}_{visit}_visual_{task}_button_specgramsR.pkl')\n",
    "            save.pickle(specgramsL_lh, f'{output_folder}/{subject[:5]}_{visit}_visual_{task}_button_specgramsL_lh.pkl')\n",
    "            save.pickle(specgramsR_lh, f'{output_folder}/{subject[:5]}_{visit}_visual_{task}_button_specgramsR_lh.pkl')\n",
    "            save.pickle(specgramsL_rh, f'{output_folder}/{subject[:5]}_{visit}_visual_{task}_button_specgramsL_rh.pkl')\n",
    "            save.pickle(specgramsR_rh, f'{output_folder}/{subject[:5]}_{visit}_visual_{task}_button_specgramsR_rh.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72754f58-0023-4313-a777-492992d07aec",
   "metadata": {
    "tags": []
   },
   "source": [
    "# write CSV file ERD ERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb16f208-ced0-4635-a38c-a50975cff75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for computing ERD, ERS\n",
    "def get_ERD_ERS(ev, f1=13, f2=25):\n",
    "    tbaseline = (-2.9,-2)\n",
    "    RELBASE = ev.sub(frequency=(f1,f2)).mean('frequency').sub(time=tbaseline).mean('time') / ev.sub(time=tbaseline).mean('frequency').mean('time')\n",
    "    ev = ev.sub(frequency=(f1,f2)).mean('frequency')\n",
    "    BASE = ev.sub(time=tbaseline).mean('time')\n",
    "    normf = ev.sub(time=tbaseline).mean('time')\n",
    "    ts1 = -1\n",
    "    te1 = 0.5\n",
    "    ERD = -(ev.sub(time=(ts1,te1)).mean('time') - normf)/normf\n",
    "    ts2 = 0.5\n",
    "    te2 = 2.5\n",
    "    ERS = (ev.sub(time=(ts2,te2)).mean('time') - normf)/normf\n",
    "    if ERD <= 0:\n",
    "        ERD = ''\n",
    "    if ERS <= 0:\n",
    "        ERS = ''\n",
    "    return ERD, ERS, BASE, RELBASE\n",
    "\n",
    "def get_ERD_ERS_trials(ev):\n",
    "    ERDs = []\n",
    "    ERSs = []\n",
    "    BASEs = []\n",
    "    RELBASEs = []\n",
    "    ntrials = 0  \n",
    "    for ii in range(len(ev)):\n",
    "        ERD, ERS, BASE, RELBASE = get_ERD_ERS(ev[ii])\n",
    "        if ERD!='':\n",
    "            ERDs.append(ERD)\n",
    "        if ERS!='':\n",
    "            ERSs.append(ERS)        \n",
    "        BASEs.append(BASE)\n",
    "        RELBASEs.append(RELBASE)\n",
    "        ntrials += 1\n",
    "    if len(ERDs) == 0:\n",
    "        ERD = ''\n",
    "    else:\n",
    "        ERD = np.sum(ERDs)/ntrials\n",
    "    if len(ERSs) == 0:\n",
    "        ERS = ''\n",
    "    else:\n",
    "        ERS = np.sum(ERSs)/ntrials\n",
    "    BASE = np.sum(BASEs)/ntrials\n",
    "    RELBASE = np.sum(RELBASEs)/ntrials\n",
    "    return ERD, ERS, BASE, RELBASE\n",
    "\n",
    "\n",
    "\n",
    "CONTROLS = ['R2517', 'R2519', 'R2520', 'R2521', 'R2525', 'R2528', 'R2496', 'R2673',] \n",
    "PATIENTS = ['R2527', 'R2540', 'R2546', 'R2598', 'R2615', 'R2617', 'R2664', 'R2667', 'R2668',]\n",
    "subjects = CONTROLS + PATIENTS\n",
    "# lesion hemisphere\n",
    "LEFT =  ['R2527', 'R2540', 'R2667', 'R2668']\n",
    "RIGHT = ['R2546', 'R2598', 'R2615', 'R2617', 'R2664']\n",
    "\n",
    "beta_band = (13, 25)\n",
    "psdrange = (2, 40)\n",
    "\n",
    "outfile = 'ERD_ERS.csv'\n",
    "with open(outfile, 'w+') as f:\n",
    "    f.write(f'subject,group,value,metric,visit,task\\n') # column headings\n",
    "    \n",
    "# lesion hemisphere button\n",
    "outfile2 = 'ERD_ERS_lesionhemi.csv'\n",
    "with open(outfile2, 'w+') as f:\n",
    "    f.write(f'subject,group,value,metric,hemi,lesion,visit,task\\n') # column headings \n",
    "    \n",
    "for subject in subjects:\n",
    "    if subject == 'R26672':\n",
    "        continue\n",
    "    for visit in ['visit1', 'visit2']:\n",
    "        for task in ['mm', 'pn', 'pd']:\n",
    "            infile = f'{subject}_{visit}_visual_{task}_button_specgramsL.pkl'\n",
    "            if not os.path.exists(f'{output_folder}/{infile}'):\n",
    "                print(f'file not found: {infile}')\n",
    "                continue\n",
    "            print(f'loading: {infile}')\n",
    "            specL = load.unpickle(f'{output_folder}/{infile}')\n",
    "            specR = load.unpickle(f'{output_folder}/{subject}_{visit}_visual_{task}_button_specgramsR.pkl')\n",
    "            \n",
    "            spec = combine([combine(specL),combine(specR)])\n",
    "            ERD, ERS, BASE, RELBASE = get_ERD_ERS_trials(spec)\n",
    "            \n",
    "            if subject in CONTROLS:\n",
    "                group = 'C'\n",
    "            else:\n",
    "                group = 'P'\n",
    "            \n",
    "            spec_lh = combine([combine(specR_lh), combine(specL_lh)])\n",
    "            spec_rh = combine([combine(specR_rh), combine(specL_rh)])\n",
    "            \n",
    "            ERD_lh, ERS_lh, _, _ = get_ERD_ERS_trials(spec_lh)\n",
    "            ERD_rh, ERS_rh, _, _ = get_ERD_ERS_trials(spec_rh)\n",
    "            \n",
    "            \n",
    "            with open(outfile, 'a+') as f:\n",
    "                f.write(f'{subject},{group},{ERD},ERD,{visit},{task}\\n')\n",
    "                f.write(f'{subject},{group},{ERS},ERS,{visit},{task}\\n')\n",
    "                f.write(f'{subject},{group},{BASE},BASE,{visit},{task}\\n')\n",
    "                f.write(f'{subject},{group},{RELBASE},RELBASE,{visit},{task}\\n')\n",
    "\n",
    "            with open(outfile2, 'a+') as f:\n",
    "                if subject in LEFT:\n",
    "                    f.write(f'{subject},{group},{ERD_lh},ERD,left,ipsi,{visit},{task}\\n')\n",
    "                    f.write(f'{subject},{group},{ERS_lh},ERS,left,ipsi,{visit},{task}\\n')\n",
    "                    f.write(f'{subject},{group},{ERD_rh},ERD,right,contra,{visit},{task}\\n')\n",
    "                    f.write(f'{subject},{group},{ERS_rh},ERS,right,contra,{visit},{task}\\n')\n",
    "                elif subject in RIGHT:\n",
    "                    f.write(f'{subject},{group},{ERD_lh},ERD,left,contra,{visit},{task}\\n')\n",
    "                    f.write(f'{subject},{group},{ERS_lh},ERS,left,contra,{visit},{task}\\n')\n",
    "                    f.write(f'{subject},{group},{ERD_rh},ERD,right,ipsi,{visit},{task}\\n')\n",
    "                    f.write(f'{subject},{group},{ERS_rh},ERS,right,ipsi,{visit},{task}\\n')\n",
    "                else:\n",
    "                    f.write(f'{subject},{group},{ERD_lh},ERD,left,,{visit},{task}\\n')\n",
    "                    f.write(f'{subject},{group},{ERS_lh},ERS,left,,{visit},{task}\\n')\n",
    "                    f.write(f'{subject},{group},{ERD_rh},ERD,right,,{visit},{task}\\n')\n",
    "                    f.write(f'{subject},{group},{ERS_rh},ERS,right,,{visit},{task}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
